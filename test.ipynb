{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import helper_pytorch as H\n",
    "\n",
    "from dataset import Dataset\n",
    "from post_processing import post_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"uacanet\"\n",
    "run_id = 0\n",
    "ckpt_path = f\"./ckpts/{run_name}{run_id}\"\n",
    "model_valid_path = f\"{ckpt_path}/model_valid.pt\"\n",
    "history_path = f\"{ckpt_path}/history.csv\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = H.UNet(\n",
    "#     capacity=64,\n",
    "#     n_classes=4,\n",
    "#     n_channels=1\n",
    "# )\n",
    "# model = H.resnet18(\n",
    "#     capacity=64,\n",
    "#     n_classes=4,\n",
    "#     in_channels=1\n",
    "# )\n",
    "# model = H.CE_Net_(\n",
    "#     num_channels=1,\n",
    "#     num_classes=4\n",
    "# )\n",
    "model = H.UACANet(\n",
    "    n_channels=1,\n",
    "    n_classes=4,\n",
    "    pretrained=False,\n",
    ")\n",
    "# model = H.segmenter(\n",
    "#     img_height=352,\n",
    "#     img_width=math.ceil(1250*np.pi/16)*16,\n",
    "# )\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_valid_path)['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.plot_history(history_path, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset(\n",
    "    split='test',\n",
    "    do_transform=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, gt = test_dataset[2]\n",
    "img = torch.unsqueeze(img, 0)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for i, img_gt in enumerate(tqdm(test_dataset)):\n",
    "    img = img_gt[0]\n",
    "    img = torch.unsqueeze(img, 0)\n",
    "    img = img.to(device)\n",
    "\n",
    "    pred = model(img)\n",
    "\n",
    "    pred = pred[0].detach().cpu().numpy().argmax(axis=0)\n",
    "\n",
    "    pred = post_processing(pred)\n",
    "\n",
    "    gt = cv2.imread(f\"./data/test/gts/{test_dataset.files[i]}\", cv2.IMREAD_GRAYSCALE)\n",
    "    gt[gt==11] = 3\n",
    "    gt[gt==9] = 2\n",
    "\n",
    "    dscs = H.dice_np(\n",
    "        gts=gt,\n",
    "        preds=pred,\n",
    "        n_classes=4\n",
    "    )\n",
    "\n",
    "    results.append(dscs)\n",
    "\n",
    "    del img, img_gt, pred\n",
    "\n",
    "results = np.array(results).transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = {\n",
    "    \"closest_to_mean_index\": np.abs(results[3]-results[3].mean()).argmin(axis=0),\n",
    "    \"max_index\": results[3].argmax(),\n",
    "    \"min_index\": results[3].argmin(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in indexes.items():\n",
    "    img, gt = test_dataset[item]\n",
    "    img = torch.unsqueeze(img, 0)\n",
    "    img = img.to(device)\n",
    "\n",
    "    pred = model(img)\n",
    "\n",
    "    pred = pred[0].detach().cpu().numpy().argmax(axis=0)\n",
    "    \n",
    "    pred = post_processing(pred)\n",
    "\n",
    "    gt = cv2.imread(f\"./data/test/gts/{test_dataset.files[item]}\", cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.imread(f\"./data/test/images/{test_dataset.files[item]}\")/255\n",
    "\n",
    "    gt[gt==11] = 3\n",
    "    gt[gt==9] = 2\n",
    "\n",
    "    dscs = H.dice_np(\n",
    "        gts=gt,\n",
    "        preds=pred,\n",
    "        n_classes=4\n",
    "    )\n",
    "\n",
    "    H.plot_single_data(\n",
    "        img,\n",
    "        gt,\n",
    "        pred,\n",
    "        monitor_class=3,\n",
    "        figsize=(30, 10),\n",
    "        opacity=0.2,\n",
    "        suptitle=f\"dsc: {dscs[3]}\"\n",
    "    )\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
